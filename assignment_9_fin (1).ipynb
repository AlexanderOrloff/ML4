{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "assignment_9_fin.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "69aa74ca5e5e4f2e97ff8e5568accbae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_705753992ba04911bc3b031e4d985cea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d93f4f3c5dec4040a6c4a07039f52790",
              "IPY_MODEL_322b544ffe164aef8732d8a9cc184638"
            ]
          }
        },
        "705753992ba04911bc3b031e4d985cea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d93f4f3c5dec4040a6c4a07039f52790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_446d97ffe38d4533a7f8327bb02f07b1",
            "_dom_classes": [],
            "description": "Epoch 1:   0%",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 717,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fbf1837b0a3146c785ed6cb2c1faeafd"
          }
        },
        "322b544ffe164aef8732d8a9cc184638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_14507dd721aa42899b5c78c742b47369",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/717 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d4bb04053a4482d9445493f9f7f652f"
          }
        },
        "446d97ffe38d4533a7f8327bb02f07b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fbf1837b0a3146c785ed6cb2c1faeafd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14507dd721aa42899b5c78c742b47369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d4bb04053a4482d9445493f9f7f652f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuMyevR2w0Fa",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 9\n",
        "\n",
        "Use data from `https://github.com/thedenaas/hse_seminars/tree/master/2018/seminar_13/data.zip`  \n",
        "Implement model in pytorch from [\"An Unsupervised Neural Attention Model for Aspect Extraction, He et al, 2017\"](https://www.comp.nus.edu.sg/~leews/publications/acl17.pdf), also desribed in seminar notes.  \n",
        "\n",
        "\n",
        "You can use sentence embeddings with attention **[7 points]**:  \n",
        "$z_s = \\sum_{i}^n \\alpha_i e_{w_i}, z_s \\in R^d$ sentence embedding  \n",
        "$\\alpha_i = softmax(d_i)$  attention weight for i-th token  \n",
        "$d_i = e_{w_i}^T M y_s$ attention with trainable matrix $M \\in R^{dxd}$  \n",
        "$y_s = \\frac 1 n \\sum_{i=1}^n e_{w_i}, y_s \\in R^d$ sentence context  \n",
        "$e_{w_i} \\in R^d$, token embedding of size d  \n",
        "$n$ - number of tokens in a sentence  \n",
        "\n",
        "**Or** just use sentence embedding as an average over word embeddings **[5 points]**:  \n",
        "$z_s = \\frac 1 n \\sum_{i=1}^n e_{w_i}, z_s \\in R^d$ sentence embedding  \n",
        "$e_{w_i} \\in R^d$, token embedding of size d  \n",
        "$n$ - number of tokens in a sentence  \n",
        " \n",
        "$p_t = softmax(W z_s + b), p_t \\in R^K$ topic weights for sentence $s$, with trainable matrix $W \\in R^{dxK}$ and bias vector $b \\in R^K$  \n",
        "$r_s = T^T p_t, r_s \\in R^d$ reconstructed sentence embedding as a weighted sum of topic embeddings   \n",
        "$T \\in R^{Kxd}$ trainable matrix of topic embeddings, K=number of topics\n",
        "\n",
        "\n",
        "**Training objective**:\n",
        "$$ J = \\sum_{s \\in D} \\sum_{i=1}^m max(0, 1-r_s^T z_s + r_s^T n_i) + \\lambda ||T^T T - I ||^2_F  $$\n",
        "where   \n",
        "$m$ random sentences are sampled as negative examples from dataset $D$ for each sentence $s$  \n",
        "$n_i = \\frac 1 n \\sum_{i=j}^n e_{w_j}$ average of word embeddings in the i-th sentence  \n",
        "$||T^T T - I ||_F$ regularizer, that enforces matrix $T$ to be orthogonal  \n",
        "$||A||^2_F = \\sum_{i=1}^N\\sum_{j=1}^M a_{ij}^2, A \\in R^{NxM}$ Frobenius norm\n",
        "\n",
        "\n",
        "**[3 points]** Compute topic coherence for at least for 3 different number of topics. Use 10 nearest words for each topic. It means you have to train one model for each number of topics. You can use code from seminar notes with word2vec similarity scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRABeksSAco0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch as tt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchtext.data import Field, TabularDataset, Iterator\n",
        "\n",
        "from tqdm import tqdm, tqdm_notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA-Afo7HI1PI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "random_state = 42\n",
        "num_neg_samples = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czt2JCSVw0Fe",
        "colab_type": "code",
        "outputId": "5b11c9a3-32f8-40ff-9c98-78c6ac68aee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "!wget -O data.zip https://github.com/thedenaas/hse_seminars/blob/master/2018/seminar_13/data.zip?raw=true "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-22 16:51:38--  https://github.com/thedenaas/hse_seminars/blob/master/2018/seminar_13/data.zip?raw=true\n",
            "Resolving github.com (github.com)... 140.82.118.4\n",
            "Connecting to github.com (github.com)|140.82.118.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/thedenaas/hse_seminars/raw/master/2018/seminar_13/data.zip [following]\n",
            "--2020-03-22 16:51:38--  https://github.com/thedenaas/hse_seminars/raw/master/2018/seminar_13/data.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/thedenaas/hse_seminars/master/2018/seminar_13/data.zip [following]\n",
            "--2020-03-22 16:51:38--  https://raw.githubusercontent.com/thedenaas/hse_seminars/master/2018/seminar_13/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9927168 (9.5M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   9.47M  42.1MB/s    in 0.2s    \n",
            "\n",
            "2020-03-22 16:51:39 (42.1 MB/s) - ‘data.zip’ saved [9927168/9927168]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVc2yVTixVTG",
        "colab_type": "code",
        "outputId": "a1e999c5-09ac-470d-9d60-b6677b56a73a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "replace data.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: data.txt                \n",
            "replace stopwords.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: stopwords.txt           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vocSo75u0i0S",
        "colab_type": "code",
        "outputId": "6bae9d90-735a-4d9c-b758-651a49e7f954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdHPB3x4yhkR",
        "colab_type": "code",
        "outputId": "7b85ef95-b6e8-4e2e-c5a9-309d2a3161d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "with open('data.txt', 'r') as f:\n",
        "  text = f.read()\n",
        "print(text[: 1000])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Barclays' defiance of US fines has merit Barclays disgraced itself in many ways during the pre-financial crisis boom years. So it is tempting to think the bank, when asked by US Department of Justice to pay a large bill for polluting the financial system with mortgage junk between 2005 and 2007, should cough up, apologise and learn some humility. That is not the view of the chief executive, Jes Staley. Barclays thinks the DoJ’s claims are “disconnected from the facts” and that it has “an obligation to our shareholders, customers, clients and employees to defend ourselves against unreasonable allegations and demands.” The stance is possibly foolhardy, since going into open legal battle with the most powerful US prosecutor is risky, especially if you end up losing. But actually, some grudging respect for Staley and Barclays is in order. The US system for dishing out fines to errant banks for their mortgage sins has come to resemble a casino. The approach prefers settlements behind closed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh_NNHgfxo5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words = []\n",
        "with open( \"stopwords.txt\", \"r\" ) as f:\n",
        "    for line in f.readlines():\n",
        "        stop_words.append( line.strip().lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1mKlj4sFdPs",
        "colab_type": "text"
      },
      "source": [
        "### add negative samples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxr2-fhJZpxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df['data'] = nltk.tokenize.sent_tokenize(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NljMpHhpbp2f",
        "colab_type": "code",
        "outputId": "baad0ba4-c090-4958-e7c5-30e0a7c03dfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "source": [
        "df[:13]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Barclays' defiance of US fines has merit Barcl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>So it is tempting to think the bank, when aske...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>That is not the view of the chief executive, J...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Barclays thinks the DoJ’s claims are “disconne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>But actually, some grudging respect for Staley...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The US system for dishing out fines to errant ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The approach prefers settlements behind closed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Occasional leaks of the negotiating demands ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Deutsche Bank was initially asked for $14bn (£...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Where is the rhyme or reason?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>There is also a strong suspicion that the roul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>US banks, in the forms of JP Morgan, Goldman S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>If Barclays created and distributed far fewer ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 data\n",
              "0   Barclays' defiance of US fines has merit Barcl...\n",
              "1   So it is tempting to think the bank, when aske...\n",
              "2   That is not the view of the chief executive, J...\n",
              "3   Barclays thinks the DoJ’s claims are “disconne...\n",
              "4   But actually, some grudging respect for Staley...\n",
              "5   The US system for dishing out fines to errant ...\n",
              "6   The approach prefers settlements behind closed...\n",
              "7   Occasional leaks of the negotiating demands ma...\n",
              "8   Deutsche Bank was initially asked for $14bn (£...\n",
              "9                       Where is the rhyme or reason?\n",
              "10  There is also a strong suspicion that the roul...\n",
              "11  US banks, in the forms of JP Morgan, Goldman S...\n",
              "12  If Barclays created and distributed far fewer ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nDot0OQ2Puj",
        "colab_type": "text"
      },
      "source": [
        "Я думаю, что кавычки лучше просто игнорить... Внутри них есть точки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNSOBR6SLgWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_negative(df):\n",
        "  neg_id = np.random.choice(len(df))\n",
        "  return df.iloc[neg_id, 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGD371YFcaDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(num_neg_samples):\n",
        "  df[f'neg{i}'] = df['data'].apply(lambda x: add_negative(df))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWURVqRjdPyr",
        "colab_type": "code",
        "outputId": "9c2629bd-0bda-40ff-9698-8a13bb9e7f80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>neg0</th>\n",
              "      <th>neg1</th>\n",
              "      <th>neg2</th>\n",
              "      <th>neg3</th>\n",
              "      <th>neg4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Barclays' defiance of US fines has merit Barcl...</td>\n",
              "      <td>Perhaps English football’s ability to particip...</td>\n",
              "      <td>She had been so mute on Europe that it was an ...</td>\n",
              "      <td>There are the nurses who offer you their secre...</td>\n",
              "      <td>Hundreds of thousands of users say Twitter is ...</td>\n",
              "      <td>Anushka Asthana is joined by Gary Younge, Rand...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>So it is tempting to think the bank, when aske...</td>\n",
              "      <td>With delicious timing, ARM’s half-year results...</td>\n",
              "      <td>MPs and peers are demanding a full inquiry by ...</td>\n",
              "      <td>George, who signed off: “I rely entirely on yo...</td>\n",
              "      <td>It’s all going off!</td>\n",
              "      <td>He anticipated the international community, mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>That is not the view of the chief executive, J...</td>\n",
              "      <td>So why didn’t this apply to the banking sector?</td>\n",
              "      <td>“They were part-time jobs,” he said.</td>\n",
              "      <td>“Maybe we are not experienced enough in a situ...</td>\n",
              "      <td>They were still there!” The bottom line, she t...</td>\n",
              "      <td>Well, that was a rather unexpected ending to t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Barclays thinks the DoJ’s claims are “disconne...</td>\n",
              "      <td>The same study detailed how people with panic ...</td>\n",
              "      <td>I can take our party to victory.</td>\n",
              "      <td>The government has taken a number of steps and...</td>\n",
              "      <td>The latest edition is the start of a miniserie...</td>\n",
              "      <td>This time Burnley win the ball.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>But actually, some grudging respect for Staley...</td>\n",
              "      <td>But would parents know where to look and if th...</td>\n",
              "      <td>“Trump is not a career politician,” he said.</td>\n",
              "      <td>The amount of $14 billion which was initially ...</td>\n",
              "      <td>Juxtaposed with its backdrop of a cheerful lat...</td>\n",
              "      <td>I’m very short-sighted and was nervous.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183395</th>\n",
              "      <td>It feels as though Stone realised that some of...</td>\n",
              "      <td>There is a church in every village and distric...</td>\n",
              "      <td>It said Bourdieu and leading lady Géraldine Pa...</td>\n",
              "      <td>What Griffiths has said could be seen as pre-e...</td>\n",
              "      <td>Mauricio Pochettino’s side are hardly in good ...</td>\n",
              "      <td>A few results are beginning to trickle in from...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183396</th>\n",
              "      <td>There are some fun elements, many involving Rh...</td>\n",
              "      <td>When I first moved here six years ago I found ...</td>\n",
              "      <td>I keep trying to figure out if he knows, or ca...</td>\n",
              "      <td>George Lucas could invent an entire religion t...</td>\n",
              "      <td>But this is such a bracing and optimistic and ...</td>\n",
              "      <td>“We’re disappointed that ad blocking companies...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183397</th>\n",
              "      <td>I particularly enjoyed a scene in which O’Bria...</td>\n",
              "      <td>The comparable figure 12 months ago was 4.2% a...</td>\n",
              "      <td>McCarthy was crushed by the ultra-conservative...</td>\n",
              "      <td>Translated as “black market’ in Japanese, the ...</td>\n",
              "      <td>Iowa has sent notice that the Republican nomin...</td>\n",
              "      <td>It’s maddening.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183398</th>\n",
              "      <td>His carnivorous snarl fills the immense screen...</td>\n",
              "      <td>The new ad by Future 45 shows Clinton talking ...</td>\n",
              "      <td>They went through the middle and so I asked th...</td>\n",
              "      <td>The Greens and Lib Dems seem ready to play.</td>\n",
              "      <td>The content, its lies and contradictions, were...</td>\n",
              "      <td>So it is misleading to describe Zika as “yet a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183399</th>\n",
              "      <td>There’s a playful visual flair to this moment ...</td>\n",
              "      <td>This was not adequately reflected at this year...</td>\n",
              "      <td>Over the next two and a half hours, I’ll be yo...</td>\n",
              "      <td>Eurogroup chief Jeroen Dijsselbloem has weighe...</td>\n",
              "      <td>It is an essay, a fantasia, a Shakespearean co...</td>\n",
              "      <td>The researchers did not delve into the reasons...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>183400 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     data  ...                                               neg4\n",
              "0       Barclays' defiance of US fines has merit Barcl...  ...  Anushka Asthana is joined by Gary Younge, Rand...\n",
              "1       So it is tempting to think the bank, when aske...  ...  He anticipated the international community, mi...\n",
              "2       That is not the view of the chief executive, J...  ...  Well, that was a rather unexpected ending to t...\n",
              "3       Barclays thinks the DoJ’s claims are “disconne...  ...                    This time Burnley win the ball.\n",
              "4       But actually, some grudging respect for Staley...  ...            I’m very short-sighted and was nervous.\n",
              "...                                                   ...  ...                                                ...\n",
              "183395  It feels as though Stone realised that some of...  ...  A few results are beginning to trickle in from...\n",
              "183396  There are some fun elements, many involving Rh...  ...  “We’re disappointed that ad blocking companies...\n",
              "183397  I particularly enjoyed a scene in which O’Bria...  ...                                    It’s maddening.\n",
              "183398  His carnivorous snarl fills the immense screen...  ...  So it is misleading to describe Zika as “yet a...\n",
              "183399  There’s a playful visual flair to this moment ...  ...  The researchers did not delve into the reasons...\n",
              "\n",
              "[183400 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAKc5GNiYVbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT = Field(include_lengths=False, \n",
        "             batch_first=True, \n",
        "             tokenize=nltk.tokenize.word_tokenize,\n",
        "             lower=True,\n",
        "             stop_words=stop_words)\n",
        "\n",
        "datafields = [('data',TEXT), *[(f'neg{i}', TEXT) for i in range(num_neg_samples)]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olbrxIToduax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('text.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnHbWGJBgbcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn = TabularDataset(path=\"text.csv\",\n",
        "                     format='csv',\n",
        "                     skip_header=True,\n",
        "                     fields=datafields)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_lSBb1kfWoD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT.build_vocab(trn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NuFSL9TfxEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = len(TEXT.vocab.itos) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3_GqGh3BN9Z",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opILml5cgINj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trn_itr = Iterator(trn, batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MW8c2395Tgu",
        "colab_type": "code",
        "outputId": "4858e05b-55df-428b-e16a-219e1c6ac508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pad_id = TEXT.vocab.stoi['<pad>']\n",
        "pad_id"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyWZz9XSBNVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, emb_dim=300, topic_dim=5):\n",
        "      super(MyModel, self).__init__()\n",
        "      self.embedding = nn.EmbeddingBag(vocab_size, emb_dim)  ## how do I ignore the padding?\n",
        "      self.pt = nn.Linear(emb_dim, topic_dim)\n",
        "      self.soft = F.softmax\n",
        "      self.rs = nn.Linear(topic_dim, emb_dim, bias=False)\n",
        "\n",
        "    def forward(self, batch):\n",
        "      emb_x = self.embedding(batch.data)\n",
        "      x = self.pt(emb_x)\n",
        "      x = self.soft(x)\n",
        "      x = self.rs(x) \n",
        "      \n",
        "      negs = [self.embedding(batch.neg0), \n",
        "              self.embedding(batch.neg1), \n",
        "              self.embedding(batch.neg2),\n",
        "              self.embedding(batch.neg3),\n",
        "              self.embedding(batch.neg4),]  ## how do I generalize this to different num_neg_samples?\n",
        "      negs = tt.stack(negs, dim=-1)\n",
        "\n",
        "      return x, emb_x, negs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXbsm9ptjGUr",
        "colab_type": "code",
        "outputId": "cd97a49e-73db-4181-b807-18e7c500a13d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "example_batch = next(iter(trn_itr))\n",
        "example_batch"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.data.batch.Batch of size 256]\n",
              "\t[.data]:[torch.LongTensor of size 256x68]\n",
              "\t[.neg0]:[torch.LongTensor of size 256x87]\n",
              "\t[.neg1]:[torch.LongTensor of size 256x48]\n",
              "\t[.neg2]:[torch.LongTensor of size 256x58]\n",
              "\t[.neg3]:[torch.LongTensor of size 256x79]\n",
              "\t[.neg4]:[torch.LongTensor of size 256x112]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrocE9_AfJYU",
        "colab_type": "code",
        "outputId": "0686e946-9307-44b9-ed60-8321b599be9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "model = MyModel(vocab_size)\n",
        "x, emb_x, negs = model(example_batch)\n",
        "x.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5-u-WIK_w5j",
        "colab_type": "code",
        "outputId": "a2640089-31fc-47c4-e0b0-f83aa9a31d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "emb_x.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9mPzg4E_FRr",
        "colab_type": "code",
        "outputId": "80ada0e3-6c23-46fb-aa63-7c6c855c1cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "negs.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 300, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywj6YL-4lJB4",
        "colab_type": "code",
        "outputId": "73a13d99-5ae0-4f81-add7-6a8cfd0e113c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "list(model.parameters())[0].shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([95799, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9xMJXlK_SWV",
        "colab_type": "code",
        "outputId": "274b1b5c-432a-48ab-8e4e-f9f54054ca82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.embedding.weight.shape"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([95799, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJoYWJZUBuqi",
        "colab_type": "text"
      },
      "source": [
        "## Loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gZd0mkCFNLX",
        "colab_type": "text"
      },
      "source": [
        "**TODO FIX LAMBDA ATTR**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCpVzlItBv2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyLoss(nn.Module):\n",
        "  def init(self, lmbd=0.01):\n",
        "    super(MyLoss, self).init()\n",
        "    self.lmbd = lmbd\n",
        "\n",
        "  def forward(self, vecs_true, negs, vecs_rec, T):\n",
        "    vecs_true = vecs_true.unsqueeze(1) ## add dimension for bmm\n",
        "    rs = vecs_rec.unsqueeze(1) ## add dimension for bmm\n",
        "    rsT = rs.permute(0, 2, 1) ## transpose\n",
        "    rsTzs = tt.bmm(rsT, vecs_true)\n",
        "    negs_losses = []\n",
        "    for ni in negs.permute(2, 0, 1):  ## so that we iterate over the neg samples\n",
        "      ni = ni.unsqueeze(1) ## add dimension for bmm\n",
        "      negs_losses.append(tt.bmm(rsT, ni))\n",
        "    losses = []\n",
        "    for n_loss in negs_losses:\n",
        "      tmp = (1 - rsTzs + n_loss).squeeze(1)\n",
        "      zeros = tt.zeros_like(tmp)\n",
        "      values, idx = tt.max(tt.stack([tmp, zeros]), 0)\n",
        "      losses.append(values)\n",
        "    losses = tt.stack(losses, dim=-1)\n",
        "    reg_0 = tt.mm(T.permute(1,0), T)\n",
        "    reg = (tt.norm(reg_0 - tt.eye(reg_0.shape[0]), p='fro')) #self.lmbd \n",
        "    return tt.sum(losses) + reg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YUFsnQFsh8L",
        "colab_type": "code",
        "outputId": "57eeb523-4f13-4ed7-9182-43052a757d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "criterion = MyLoss()\n",
        "\n",
        "criterion(emb_x, negs, x, model.embedding.weight)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.1686e+08, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V97gWI-5vuEB",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sm_8gYlvz6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs = 2\n",
        "optimizer = tt.optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yngRqDkbiEIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(data_iter, len_iter, n_epoch, model, criterion, optimizer=None):\n",
        "    train_losses = []\n",
        "    total_loss = 0\n",
        "    data_iter = tqdm_notebook(data_iter, total=len_iter, desc=f\"Epoch {n_epoch + 1}\", leave=True)\n",
        "    counter = 0\n",
        "    for batch in data_iter:\n",
        "        if optimizer:\n",
        "          optimizer.zero_grad()\n",
        "        vec_rec = model.forward(batch)\n",
        "        loss = criterion(batch.vecs, batch.negs, vec_rec,list(model.parameters())[-1])\n",
        "        loss.backward()\n",
        "        if optimizer:\n",
        "          optimizer.step()\n",
        "        loss_value = loss.detach().item()\n",
        "        total_loss += loss_value\n",
        "        train_losses.append(loss_value)\n",
        "        data_iter.set_postfix(loss = loss_value)\n",
        "        counter += 1\n",
        "        \n",
        "    total_loss /= counter\n",
        "    return total_loss, train_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwsvdLievvtl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495,
          "referenced_widgets": [
            "69aa74ca5e5e4f2e97ff8e5568accbae",
            "705753992ba04911bc3b031e4d985cea",
            "d93f4f3c5dec4040a6c4a07039f52790",
            "322b544ffe164aef8732d8a9cc184638",
            "446d97ffe38d4533a7f8327bb02f07b1",
            "fbf1837b0a3146c785ed6cb2c1faeafd",
            "14507dd721aa42899b5c78c742b47369",
            "7d4bb04053a4482d9445493f9f7f652f"
          ]
        },
        "outputId": "9f95d997-4308-4e5a-bee6-98b0cb57783f"
      },
      "source": [
        "total_train_losses = []\n",
        "total_valid_losses = []\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    loss, train_losses = train_epoch(trn_itr, len(trn_itr), epoch, model, criterion, optimizer)\n",
        "    total_train_losses += train_losses\n",
        "    print('train', loss)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69aa74ca5e5e4f2e97ff8e5568accbae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Epoch 1', max=717, style=ProgressStyle(description_width='ini…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-ffb68d6ac2bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_itr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrn_itr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtotal_train_losses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-ebc1693d911f>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(data_iter, len_iter, n_epoch, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m      8\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mvec_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec_rec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Batch' object has no attribute 'vecs'"
          ]
        }
      ]
    }
  ]
}